{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C_VY80GRe09r"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import XLNetTokenizer, TFXLNetModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY7uPvwVhT6q",
        "outputId": "d791f8ce-ad9b-40f7-e5d7-a1fe7c57a03a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEfrlvXtzHY4",
        "outputId": "0307de81-cba9-4d61-9cb1-5732f1c573a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet\n",
        "from efficientnet.tfkeras import EfficientNetB3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEnHNm_hhnXi",
        "outputId": "28237152-ef62-4b67-a16f-2ad15c5b0164"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: efficientnet in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "# Load XLNet model and tokenizer\n",
        "xlnet_model = TFXLNetModel.from_pretrained('xlnet-base-cased')\n",
        "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OF6SblUe9Wx",
        "outputId": "bd66b9fe-3e90-4c28-8a5e-756daeb12a74"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n",
            "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
            "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load EfficientNet model"
      ],
      "metadata": {
        "id": "RXRdBlss-CIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "0ryfUe8fh2Iv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYuI6YMmlY0J",
        "outputId": "a60a9537-21b3-46c4-f24b-a9da674750c2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/MultiOFF_Dataset.zip\", \"/content/Datasets/\")"
      ],
      "metadata": {
        "id": "meejDaJenY-t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/Datasets/MultiOFF_Dataset/Split Dataset'\n",
        "\n",
        "train_df = pd.read_csv(os.path.join(dataset_path, 'Training_meme_dataset.csv'))\n",
        "test_df = pd.read_csv(os.path.join(dataset_path, 'Testing_meme_dataset.csv'))\n",
        "val_df = pd.read_csv(os.path.join(dataset_path, 'Validation_meme_dataset.csv'))"
      ],
      "metadata": {
        "id": "pBhpq219ktgq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = '/content/Datasets/MultiOFF_Dataset/Labelled Images'\n",
        "train_df['image_name'] = train_df['image_name'].apply(lambda x: os.path.join(image_folder, x))\n",
        "test_df['image_name'] = test_df['image_name'].apply(lambda x: os.path.join(image_folder, x))\n",
        "val_df['image_name'] = val_df['image_name'].apply(lambda x: os.path.join(image_folder, x))"
      ],
      "metadata": {
        "id": "PkH4kuQFsmXB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jOaYjiX0tLzk",
        "outputId": "da65d2e7-9c10-45b5-965c-63db9e1077de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          image_name  \\\n",
              "0  /content/Datasets/MultiOFF_Dataset/Labelled Im...   \n",
              "1  /content/Datasets/MultiOFF_Dataset/Labelled Im...   \n",
              "2  /content/Datasets/MultiOFF_Dataset/Labelled Im...   \n",
              "3  /content/Datasets/MultiOFF_Dataset/Labelled Im...   \n",
              "4  /content/Datasets/MultiOFF_Dataset/Labelled Im...   \n",
              "\n",
              "                                            sentence         label  \n",
              "0  OFFICIAL BERNIE SANDERS DRINKING GAME ! Every ...  Non-offensiv  \n",
              "1  2:28 PM THIS IS A WALL INSIDE A NAZI GAS CHAMB...     offensive  \n",
              "2                o shit waddup ! BERNIE SANDERS COM      offensive  \n",
              "3  `` MITT ROMNEY IS THE WORST REPUBLICAN IN THE ...  Non-offensiv  \n",
              "4  Anonymous ( ID : duqdA1io a 08/05/16 ( Fri ) 1...  Non-offensiv  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ba3dfc-cf92-4d91-989b-37ed76b59ff4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/Datasets/MultiOFF_Dataset/Labelled Im...</td>\n",
              "      <td>OFFICIAL BERNIE SANDERS DRINKING GAME ! Every ...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/Datasets/MultiOFF_Dataset/Labelled Im...</td>\n",
              "      <td>2:28 PM THIS IS A WALL INSIDE A NAZI GAS CHAMB...</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/Datasets/MultiOFF_Dataset/Labelled Im...</td>\n",
              "      <td>o shit waddup ! BERNIE SANDERS COM</td>\n",
              "      <td>offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/Datasets/MultiOFF_Dataset/Labelled Im...</td>\n",
              "      <td>`` MITT ROMNEY IS THE WORST REPUBLICAN IN THE ...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/Datasets/MultiOFF_Dataset/Labelled Im...</td>\n",
              "      <td>Anonymous ( ID : duqdA1io a 08/05/16 ( Fri ) 1...</td>\n",
              "      <td>Non-offensiv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ba3dfc-cf92-4d91-989b-37ed76b59ff4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e1ba3dfc-cf92-4d91-989b-37ed76b59ff4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e1ba3dfc-cf92-4d91-989b-37ed76b59ff4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b981941d-f9ff-4abb-99dd-abe211694263\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b981941d-f9ff-4abb-99dd-abe211694263')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b981941d-f9ff-4abb-99dd-abe211694263 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "import cv2\n",
        "\n",
        "def preprocess_image(image):\n",
        "    target_size = (224, 224)\n",
        "\n",
        "    # Resize the image\n",
        "    if isinstance(target_size, tuple) and len(target_size) == 2 and target_size[0] > 0 and target_size[1] > 0:\n",
        "        if image.shape[:2] != target_size:\n",
        "            image_resized = cv2.resize(image, target_size)\n",
        "        else:\n",
        "            image_resized = image\n",
        "\n",
        "    # Ensure the image has 3 channels\n",
        "    if len(image_resized.shape) == 2:\n",
        "        image_resized = cv2.cvtColor(image_resized, cv2.COLOR_GRAY2RGB)\n",
        "    elif image_resized.shape[2] == 4:\n",
        "        image_resized = image_resized[:, :, :3]  # Keep only the first 3 channels\n",
        "\n",
        "    # Apply preprocessing specific to EfficientNet\n",
        "    preprocessed_image = preprocess_input(image_resized)\n",
        "\n",
        "    return preprocessed_image\n"
      ],
      "metadata": {
        "id": "2HRWE8V1dVbp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_df(df):\n",
        "    image_samples = []\n",
        "\n",
        "    for image_name in df['image_name']:\n",
        "        image = Image.open(image_name)\n",
        "        image_array = np.array(image)  # Convert Image to numpy array\n",
        "        preprocessed_image = preprocess_image(image_array)\n",
        "        image_samples.append(preprocessed_image)\n",
        "\n",
        "    return image_samples"
      ],
      "metadata": {
        "id": "PH9mVX0StnLW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_train = load_images_from_df(train_df)\n",
        "image_test = load_images_from_df(test_df)\n",
        "image_val = load_images_from_df(val_df)"
      ],
      "metadata": {
        "id": "WPaydIC4uLYx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def build_model(hp):\n",
        "    # Create a Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Hyperparameter: Number of convolutional layers\n",
        "    num_conv_layers = hp.Int('num_conv_layers', min_value=1, max_value=4, step=1)\n",
        "\n",
        "    # Add convolutional layers\n",
        "    for i in range(num_conv_layers):\n",
        "        model.add(Conv2D(\n",
        "            filters=hp.Int(f'conv_{i}_filters', min_value=16, max_value=128, step=16),\n",
        "            kernel_size=hp.Choice(f'conv_{i}_kernel_size', values=[3, 5]),\n",
        "            activation='relu',\n",
        "            padding='same'\n",
        "        ))\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten the feature maps\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Hyperparameter: Number of dense layers\n",
        "    num_dense_layers = hp.Int('num_dense_layers', min_value=1, max_value=3, step=1)\n",
        "\n",
        "    # Add dense layers\n",
        "    for i in range(num_dense_layers):\n",
        "        model.add(Dense(\n",
        "            units=hp.Int(f'dense_{i}_units', min_value=32, max_value=512, step=32),\n",
        "            activation='relu'\n",
        "        ))\n",
        "        model.add(Dropout(rate=hp.Float(f'dense_{i}_dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
        "\n",
        "    # Hyperparameter: Learning rate\n",
        "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate),\n",
        "        loss='binary_crossentropy',  # Assuming binary classification\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "In7dD_FtT6I9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_train = train_df['sentence'].tolist()\n",
        "text_test = test_df['sentence'].tolist()\n",
        "text_val = val_df['sentence'].tolist()\n",
        "len(text_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IRCt0176Jo3",
        "outputId": "587a5445-3a13-4a72-9a55-b41f604a3c19"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "445"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train = train_df['label'].values\n",
        "labels_test = test_df['label'].values\n",
        "labels_val = val_df['label'].values"
      ],
      "metadata": {
        "id": "au3rYqpf6V7-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_mapping = {'Non-offensiv': 0, 'offensive': 1}\n",
        "labels_train = np.array([label_mapping[label] for label in labels_train])\n",
        "labels_test = np.array([label_mapping[label] for label in labels_test])\n",
        "labels_val = np.array([label_mapping[label] for label in labels_val])"
      ],
      "metadata": {
        "id": "w12y53aO51C3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nlpaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GUMmyuC0YzB",
        "outputId": "344fa8b4-b57d-4199-ccf7-6c06f176c180"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nlpaug in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary library\n",
        "import nlpaug.augmenter.word as naw\n",
        "# Define a function for text data augmentation\n",
        "def augment_text_data(text_data):\n",
        "    # Initialize the augmentation object\n",
        "    aug = naw.SynonymAug(aug_src='wordnet')\n",
        "    return aug.augment(text_data)\n"
      ],
      "metadata": {
        "id": "eKHyDOsazxZn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "llFs5eqp51X2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data_generator = ImageDataGenerator(\n",
        "    rotation_range=8,      # Random rotation (degrees)\n",
        "    width_shift_range=0.2,  # Random horizontal shift\n",
        "    height_shift_range=0.2, # Random vertical shift\n",
        "    shear_range=0.2,        # Shear intensity\n",
        "    zoom_range=0.1,         # Random zoom\n",
        "    horizontal_flip=True,   # Random horizontal flip\n",
        "    fill_mode='nearest'     # Fill mode for filling in newly created pixels\n",
        ")"
      ],
      "metadata": {
        "id": "WZCOVJwM55If"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_image = []\n",
        "for image_data in image_train:\n",
        "    image_data = image_data_generator.random_transform(image_data)"
      ],
      "metadata": {
        "id": "k8VwyA-v6Eie"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_text = []\n",
        "augmented_image = []\n",
        "max_seq_length = 128\n",
        "\n",
        "for i in range(len(text_train)):\n",
        "    swapped_idx = random.randint(0, len(text_train) - 1)\n",
        "    text_train[i] = augment_text_data(text_train[i])\n",
        "    # Tokenize and limit sequence length for text data\n",
        "    tokens = xlnet_tokenizer(text_train[i], truncation=True, padding='max_length', max_length=max_seq_length)\n",
        "    augmented_text.append(tokens)\n",
        "\n",
        "    # Preprocess the image\n",
        "    preprocessed_image = preprocess_image(image_train[swapped_idx])\n",
        "    augmented_image.append(preprocessed_image)\n",
        "\n",
        "# Combine the tokenized sequences into single strings\n",
        "augmented_text = [' '.join(tokens) for tokens in augmented_text]\n",
        "\n",
        "# Tokenize and encode the augmented text data using the XLNet tokenizer\n",
        "text_encodings = xlnet_tokenizer(augmented_text, padding=True, truncation=True, return_tensors='tf')\n",
        "\n",
        "# Get the input IDs for the text data\n",
        "input_ids = text_encodings['input_ids']\n",
        "attention_mask = text_encodings['attention_mask']\n",
        "\n",
        "# Generate embeddings for text data\n",
        "text_embeddings = xlnet_model(input_ids, attention_mask=attention_mask)[\"last_hidden_state\"]\n"
      ],
      "metadata": {
        "id": "bpoxzb7IXWkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b717422-fe5e-43f1-ef50-423f7b6910a3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8  # Adjust this for RAM usage\n",
        "num_samples = len(augmented_text)\n",
        "num_batches = (num_samples + batch_size - 1) // batch_size"
      ],
      "metadata": {
        "id": "UkhW-RfxOvz0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert image data to TensorFlow tensor\n",
        "# Ensure all images have the same dimensions\n",
        "# augmented_image = [img for img in augmented_image if img.shape == (224, 224, 3)]\n",
        "\n",
        "# Convert the list of images to a 4D NumPy array\n",
        "image_data = np.stack(augmented_image)\n",
        "\n",
        "# Convert the NumPy array to a TensorFlow tensor\n",
        "image_data = tf.convert_to_tensor(image_data, dtype=tf.float32)\n",
        "# image_data = tf.convert_to_tensor(image_data, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "w-80CX9dY2su"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGEAwK0J5Qgy",
        "outputId": "68e613f5-4b13-4313-9441-cb39e7987693"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([445, 224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process image data through EfficientNet\n",
        "image_embeddings = efficientnet_model.predict(image_data)"
      ],
      "metadata": {
        "id": "x0t0r8gc8Apz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53b7400-953d-4e59-a9c2-4378c3d3884a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 11s 220ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq5Ysw2T30rE",
        "outputId": "6c688267-dd78-48b8-a888-e50aed55aa3e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(445, 7, 7, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqG3Gg319bTd",
        "outputId": "5c556c49-40c5-4e42-c4eb-a212eac33840"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "445"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(image_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSRbwMxn9dSo",
        "outputId": "6990b518-76f5-47f5-e086-0829988327ae"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "445"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzGMsSzp9jIE",
        "outputId": "d99dadac-c936-4a41-e05a-6166893193e1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([445, 14, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Add a Dense layer to reduce the dimensionality of text embeddings\n",
        "text_embeddings = Dense(62720, activation='relu')(text_embeddings)\n"
      ],
      "metadata": {
        "id": "aM2ltVn25BD5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (previous parts of your code)\n",
        "\n",
        "# Flatten the image embeddings\n",
        "flattened_image_embeddings = tf.keras.layers.Flatten()(image_embeddings)\n",
        "# Flatten the text embeddings\n",
        "flattened_text_embeddings = tf.keras.layers.Flatten()(text_embeddings)\n",
        "\n",
        "# Concatenate the flattened text embeddings with the flattened image embeddings\n",
        "combined_embeddings = tf.concat([flattened_text_embeddings, flattened_image_embeddings], axis=1)"
      ],
      "metadata": {
        "id": "nY8Kba_q8FU1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMT5dRY0Dfb-",
        "outputId": "79c10647-e54c-4a5f-a5c6-a8b044937839"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(445, 7, 7, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDfUAwvvDlJj",
        "outputId": "ddc10d75-406b-4845-f42b-e268c0927952"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([445, 14, 62720])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ci5nVHTkDseE",
        "outputId": "6ec2b359-cb71-4085-f3ef-2e6644d2d8ac"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([445, 953344])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Create a Keras model for the image branch\n",
        "image_input = Input(shape=(7, 7, 1536), name='image_input')\n",
        "image_flattened = Flatten()(image_input)\n",
        "image_dense = Dense(128, activation='relu')(image_flattened)\n",
        "\n",
        "# Create a Keras model for the text branch\n",
        "main_input = Input(shape=(10, 62720), dtype='float32', name='main_input')  # Adjust input shape\n",
        "text_flattened = Flatten()(main_input)\n",
        "text_dense = Dense(128, activation='relu')(text_flattened)\n",
        "\n",
        "# Combine the text and image models\n",
        "combined_features = Concatenate()([text_dense, image_dense])\n",
        "combined_dense = Dense(128, activation='relu')(combined_features)\n",
        "combined_final_output = Dense(1, activation='sigmoid')(combined_dense)\n",
        "\n",
        "# Create the final model\n",
        "combined_model = Model(inputs=[main_input, image_input], outputs=combined_final_output)\n",
        "\n",
        "# Compile the model\n",
        "combined_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the summary of the model\n",
        "combined_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM9G8XQrU9Ck",
        "outputId": "a9df5cc1-59e9-4bc0-a08c-a879acb486b0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " main_input (InputLayer)     [(None, 10, 62720)]          0         []                            \n",
            "                                                                                                  \n",
            " image_input (InputLayer)    [(None, 7, 7, 1536)]         0         []                            \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 627200)               0         ['main_input[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)         (None, 75264)                0         ['image_input[0][0]']         \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 128)                  8028172   ['flatten_3[0][0]']           \n",
            "                                                          8                                       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  9633920   ['flatten_2[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 256)                  0         ['dense_2[0][0]',             \n",
            "                                                                     'dense_1[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 128)                  32896     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 1)                    129       ['dense_3[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 89948673 (343.13 MB)\n",
            "Trainable params: 89948673 (343.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# Splitting the data using indices\n",
        "indices = np.arange(len(text_embeddings))\n",
        "indices_train, indices_val, _, _ = train_test_split(\n",
        "    indices, labels_train, test_size=0.2, random_state=42\n",
        ")\n",
        "# Convert NumPy arrays to TensorFlow tensors\n",
        "indices_train_tf = tf.convert_to_tensor(indices_train)\n",
        "indices_val_tf = tf.convert_to_tensor(indices_val)\n",
        "\n",
        "X_train_text = tf.gather(text_embeddings, indices_train_tf)\n",
        "X_val_text = tf.gather(text_embeddings, indices_val_tf)\n",
        "X_train_img = tf.gather(image_embeddings, indices_train_tf)\n",
        "X_val_img = tf.gather(image_embeddings, indices_val_tf)\n",
        "y_train = tf.gather(labels_train, indices_train_tf)\n",
        "y_val = tf.gather(labels_train, indices_val_tf)"
      ],
      "metadata": {
        "id": "XARing16bdhR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Pad the text data to have a sequence length of 10\n",
        "X_train_text_padded = pad_sequences(X_train_text, maxlen=10, padding='post', truncating='post', dtype='float32')\n",
        "X_val_text_padded = pad_sequences(X_val_text, maxlen=10, padding='post', truncating='post', dtype='float32')"
      ],
      "metadata": {
        "id": "P7Zd-Pr4QKWz"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Monitor validation loss\n",
        "    patience=6,           # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True  # Restore the model weights from the epoch with the best validation loss\n",
        ")\n",
        "\n",
        "# Define a model checkpoint callback to save the best model during training\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',        # Filepath to save the best model\n",
        "    monitor='val_loss',     # Monitor validation loss\n",
        "    save_best_only=True,    # Save only the best model\n",
        "    verbose=1                # Verbosity mode, 1 for progress bar\n",
        ")"
      ],
      "metadata": {
        "id": "x0NMg7Kln-m4"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(labels_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV1_5fy5yoGd",
        "outputId": "6f30a67c-b366-4bfa-d6a4-d8450667ac82"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming labels_train contains your training labels\n",
        "unique_classes, class_counts = np.unique(labels_train, return_counts=True)\n",
        "total_samples = len(labels_train)\n",
        "\n",
        "# Calculate class weights as inversely proportional to class frequencies\n",
        "class_weights = {cls: total_samples / (len(unique_classes) * count) for cls, count in zip(unique_classes, class_counts)}"
      ],
      "metadata": {
        "id": "yFTqnozME2As"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = combined_model.fit(\n",
        "        [X_train_text_padded, X_train_img],\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=5,  # Only one epoch per iteration\n",
        "        validation_data=([X_val_text_padded, X_val_img], y_val),\n",
        "        class_weight=class_weights,\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "\n",
        "    # ... Additional training loop logic ...\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huaQYKjuoHl0",
        "outputId": "f7049062-1114-47f2-a26b-15a963183bd6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "44/45 [============================>.] - ETA: 0s - loss: 9821.9580 - accuracy: 0.4744\n",
            "Epoch 1: val_loss improved from inf to 4739.82959, saving model to best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r45/45 [==============================] - 43s 831ms/step - loss: 9725.8359 - accuracy: 0.4775 - val_loss: 4739.8296 - val_accuracy: 0.4944\n",
            "Epoch 2/5\n",
            "45/45 [==============================] - ETA: 0s - loss: 4445.5176 - accuracy: 0.5197\n",
            "Epoch 2: val_loss did not improve from 4739.82959\n",
            "45/45 [==============================] - 2s 37ms/step - loss: 4445.5176 - accuracy: 0.5197 - val_loss: 12360.3359 - val_accuracy: 0.4382\n",
            "Epoch 3/5\n",
            "45/45 [==============================] - ETA: 0s - loss: 7162.1904 - accuracy: 0.5253\n",
            "Epoch 3: val_loss did not improve from 4739.82959\n",
            "45/45 [==============================] - 1s 33ms/step - loss: 7162.1904 - accuracy: 0.5253 - val_loss: 6137.4692 - val_accuracy: 0.5506\n",
            "Epoch 4/5\n",
            "45/45 [==============================] - ETA: 0s - loss: 3463.1851 - accuracy: 0.5478\n",
            "Epoch 4: val_loss improved from 4739.82959 to 4069.75781, saving model to best_model.h5\n",
            "45/45 [==============================] - 35s 791ms/step - loss: 3463.1851 - accuracy: 0.5478 - val_loss: 4069.7578 - val_accuracy: 0.5843\n",
            "Epoch 5/5\n",
            "43/45 [===========================>..] - ETA: 0s - loss: 2641.3689 - accuracy: 0.5756\n",
            "Epoch 5: val_loss improved from 4069.75781 to 3784.06543, saving model to best_model.h5\n",
            "45/45 [==============================] - 22s 501ms/step - loss: 2615.1709 - accuracy: 0.5730 - val_loss: 3784.0654 - val_accuracy: 0.4607\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and encode the test texts\n",
        "test_encodings = xlnet_tokenizer(text_test, truncation=True, padding=True, return_tensors='tf')\n",
        "\n",
        "# Get the input IDs for the test data\n",
        "input_ids_test = test_encodings['input_ids']\n",
        "image_test = np.array(image_test)\n",
        "print(\"Image type:\", type(image_test))\n",
        "print(\"Image shape:\", image_test.shape)\n",
        "preprocessed_images = []\n",
        "\n",
        "for image_data in image_test:\n",
        "    preprocessed_image = preprocess_image(image_data)\n",
        "    preprocessed_images.append(preprocessed_image)\n",
        "\n",
        "# Convert the list of preprocessed images to a NumPy array\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "# Ensure that X_test_text has the same shape as expected by the model (sequence length of 10 and embedding size of 62720)\n",
        "# You can pad or truncate as needed\n",
        "if input_ids_test.shape[1] < 10:\n",
        "    padding_size = 10 - input_ids_test.shape[1]\n",
        "    input_ids_test = np.pad(input_ids_test, ((0, 0), (0, padding_size)), mode='constant')\n",
        "elif input_ids_test.shape[1] > 10:\n",
        "    input_ids_test = input_ids_test[:, :10]\n",
        "# Now, you can use preprocessed_images for prediction with your EfficientNet model\n",
        "X_test_img = efficientnet_model.predict(preprocessed_images)\n",
        "X_test_text = xlnet_model.predict(input_ids_test)[0]  # Assuming the model returns a tuple and we want the first element\n",
        "print(\"X_test_text shape:\", X_test_text.shape)\n",
        "print(\"X_test_img shape:\", X_test_img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj3uRpsWOoOA",
        "outputId": "1373950b-4256-479b-b94e-768bdb93527c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image type: <class 'numpy.ndarray'>\n",
            "Image shape: (149, 224, 224, 3)\n",
            "5/5 [==============================] - 4s 338ms/step\n",
            "5/5 [==============================] - 9s 53ms/step\n",
            "X_test_text shape: (149, 10, 768)\n",
            "X_test_img shape: (149, 7, 7, 1536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming X_test_text has shape (None, 10, 768)\n",
        "desired_shape = (X_test_text.shape[0], 10, 62720)\n",
        "\n",
        "# Pad with zeros if the shape is smaller, or truncate if larger\n",
        "if X_test_text.shape[2] < desired_shape[2]:\n",
        "    padding = np.zeros((desired_shape[0], 10, desired_shape[2] - X_test_text.shape[2]))\n",
        "    X_test_text_padded = np.concatenate((X_test_text, padding), axis=2)\n",
        "elif X_test_text.shape[2] > desired_shape[2]:\n",
        "    X_test_text_padded = X_test_text[:, :, :desired_shape[2]]\n",
        "else:\n",
        "    X_test_text_padded = X_test_text  # No need to pad or truncate\n",
        "\n",
        "X_test_text_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "779P2iGwWNZc",
        "outputId": "07768c0b-9f77-4ce3-db5c-5f4542e40d49"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149, 10, 62720)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the best model\n",
        "best_model = load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "Hhkp_GP0pO1x"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = best_model.predict([X_test_text_padded, X_test_img])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FarZxgBz5Ok2",
        "outputId": "4025903a-2733-437f-bef4-3436ab0d3b5a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.6\n",
        "binary_predictions = (test_predictions > threshold).astype(int)"
      ],
      "metadata": {
        "id": "1EHMoF_p6kVz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming labels_test contains the true labels for your test data\n",
        "accuracy = accuracy_score(labels_test, binary_predictions)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xpRce8P6pie",
        "outputId": "49619d06-1502-4915-970a-89d4b095a330"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.4966442953020134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "precision = precision_score(labels_test, binary_predictions)\n",
        "recall = recall_score(labels_test, binary_predictions)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjXOZ8ll7SyD",
        "outputId": "5f59199e-a935-433f-b3f2-9777efd9a617"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.40229885057471265\n",
            "Recall: 0.603448275862069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(labels_test, binary_predictions)\n",
        "print(\"F1-Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQW_thqH7YKQ",
        "outputId": "6f639a01-a6a3-4c56-e632-6b5b6c005438"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.4827586206896552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(labels_test, binary_predictions)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqn6qR_c7iaA",
        "outputId": "b71f75be-1f8a-4d6e-f3ac-0bfd96415e42"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[39 52]\n",
            " [23 35]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(labels_test, test_predictions)\n",
        "auc = roc_auc_score(labels_test, test_predictions)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"AUC:\", auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "9TPl-1BD7kQM",
        "outputId": "82276260-ba46-4a24-8a20-8bb953c3ff81"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.519704433497537\n"
          ]
        }
      ]
    }
  ]
}